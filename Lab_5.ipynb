{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce665ecd",
   "metadata": {},
   "source": [
    "# Lab 5: Web Scraping & API Interaction\n",
    "\n",
    "## Objective\n",
    "To extract data from web pages using web scraping techniques and to interact with external web services using REST and SOAP APIs. This lab demonstrates HTML parsing, RESTful communication using GET and POST methods, and SOAP-based service interaction.\n",
    "\n",
    "## Theory\n",
    "Web Scraping involves programmatically fetching and parsing HTML content from websites. Python libraries such as `requests` and `BeautifulSoup` are widely used for this purpose. REST APIs allow communication between client and server using HTTP methods and usually exchange data in JSON format. SOAP APIs use XML-based messaging and WSDL definitions, commonly used in enterprise systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025a4c0",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7578478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f58f6",
   "metadata": {},
   "source": [
    "## 2. Define Target URL and Headers (Quotes Website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_URL = \"https://quotes.toscrape.com\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "    'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "response = requests.get(TARGET_URL, headers=headers)\n",
    "html_content = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f175e2a",
   "metadata": {},
   "source": [
    "## 3. Initialize BeautifulSoup and Extract Page Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "soap = BeautifulSoup(html_content, 'lxml')\n",
    "page_title = soap.find('title').text\n",
    "print(\"Page Title:\", page_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeae1da",
   "metadata": {},
   "source": [
    "## 4. Quote Scraping Using Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_data = []\n",
    "quote_divs = soap.find_all('div', class_='quote')\n",
    "\n",
    "for quote_div in quote_divs:\n",
    "    text_element = quote_div.find('span', class_='text')\n",
    "    quote_text = text_element.text if text_element else \"N/A\"\n",
    "\n",
    "    author_element = quote_div.find('small', class_='author')\n",
    "    author_name = author_element.text if author_element else \"N/A\"\n",
    "\n",
    "    tag_list = []\n",
    "    tags_div = quote_div.find('div', class_='tags')\n",
    "    if tags_div:\n",
    "        for tag_item in tags_div.find_all('a', class_='tag'):\n",
    "            tag_list.append(tag_item.text)\n",
    "\n",
    "    quotes_data.append({\n",
    "        'quote': quote_text,\n",
    "        'author': author_name,\n",
    "        'tags': tag_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b87d76b",
   "metadata": {},
   "source": [
    "## 5. Display Extracted Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567411bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Extracted Quotes (First 3) ---\")\n",
    "for item in quotes_data[:3]:\n",
    "    print(f\"Author: {item['author']}\\nQuote: {item['quote']}\\nTags: {', '.join(item['tags'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc36eb3",
   "metadata": {},
   "source": [
    "## 6. Quote Scraping Using CSS Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_texts = soap.select('div.quote span.text')\n",
    "print(f\"Found {len(quote_texts)} quotes using CSS selector.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ca9eb",
   "metadata": {},
   "source": [
    "## 7. REST API (GET Request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://jsonplaceholder.typicode.com/todos\"\n",
    "response = requests.get(api_url)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    for item in data[:5]:\n",
    "        print(item)\n",
    "else:\n",
    "    print(\"API request failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe67225",
   "metadata": {},
   "source": [
    "## 8. REST API (POST Request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data = {\n",
    "    \"userId\": 1,\n",
    "    \"title\": \"yoo\",\n",
    "    \"completed\": False\n",
    "}\n",
    "post_response = requests.post(api_url, json=post_data)\n",
    "print(\"POST Status Code:\", post_response.status_code)\n",
    "print(\"POST Response:\", post_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b82639",
   "metadata": {},
   "source": [
    "## 9. SOAP API Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1586a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeep import Client\n",
    "wsdl_url = \"http://www.dneonline.com/calculator.asmx?WSDL\"\n",
    "client = Client(wsdl=wsdl_url)\n",
    "result = client.service.Add(intA=10, intB=20)\n",
    "print(\"SOAP Add Operation Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c4be9",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "This experiment successfully demonstrated web scraping and API interaction using Python. Quotes were extracted using both HTML class-based searching and CSS selectors. REST API communication was performed using GET and POST requests with JSON data. SOAP API interaction was implemented using a WSDL-based calculator service. Errors related to missing HTML content, incorrect selectors, and POST data transmission were identified and resolved.\n",
    "\n",
    "## Conclusion\n",
    "The lab achieved its objectives by demonstrating practical techniques for web scraping, RESTful communication, and SOAP-based service interaction. These skills are essential for modern web data extraction and system integration."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}